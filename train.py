# train.py
from src.data_preparation import get_datasets_fast
from src.model_training import setup_training_fast
from transformers import ViTForImageClassification
import torch
import json
import gc
import os


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ GPU
def monitor_gpu():
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1e9
        memory_reserved = torch.cuda.memory_reserved() / 1e9
        print(f"   GPU –ø–∞–º—è—Ç—å: –≤—ã–¥–µ–ª–µ–Ω–æ {memory_allocated:.2f}GB, –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ {memory_reserved:.2f}GB")

def main():

    gc.collect()
    torch.cuda.empty_cache()

    print("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ fine-tuning ViT –Ω–∞ fashion_mnist")
    
    print("1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    train_dataset, val_dataset, test_dataset, label_names = get_datasets_fast()
    print(f"   –ö–ª–∞—Å—Å—ã: {label_names}")
    print(f"   –†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(train_dataset)}")
    print(f"   –†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(val_dataset)}")
    print(f"   –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(test_dataset)}")

    print("2. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ViT...")
    model = ViTForImageClassification.from_pretrained(
        "WinKawaks/vit-small-patch16-224",
        num_labels=len(label_names),
        ignore_mismatched_sizes=True
    )
    
    print("3. –ó–∞–º–æ—Ä–æ–∑–∫–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è fine-tuning...")
    # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–Ω–∫–æ–¥–µ—Ä–∞, –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ–≤—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    for param in model.vit.parameters():
        param.requires_grad = False
        
    # –°—á–∏—Ç–∞–µ–º –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   –û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {trainable_params:,} –∏–∑ {total_params:,} ({trainable_params/total_params*100:.2f}%)")

    print("4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è...")
    trainer = setup_training_fast(model, train_dataset, val_dataset)

    monitor_gpu()

    print("5. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
    train_result = trainer.train()

    print("6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    trainer.save_model()
    trainer.save_state()

    print("7. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ...")
    test_results = trainer.evaluate(test_dataset)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    all_metrics = {
        "train_metrics": train_result.metrics,
        "test_metrics": test_results,
        "hyperparameters": {
            "learning_rate": 2e-4,
            "batch_size": 32,
            "epochs": 3,
            "trainable_parameters": trainable_params,
            "total_parameters": total_params
        }
    }
    
    os.makedirs("./reports", exist_ok=True)
    with open("./reports/training_metrics.json", "w") as f:
        json.dump(all_metrics, f, indent=2)
    
    print("8. –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ ./reports/training_metrics.json")
    print(f"   Final Train Loss: {train_result.metrics.get('train_loss', 'N/A')}")
    print(f"   Test Accuracy: {test_results.get('eval_accuracy', 0)*100:.2f}%")
    
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()